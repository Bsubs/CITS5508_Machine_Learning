{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "627eabfe",
   "metadata": {},
   "source": [
    "# 1 Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e2d101",
   "metadata": {},
   "source": [
    "Importing a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. \n",
    "\n",
    "Check that Python 3.5 or later is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560e2c9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Array' from 'typing' (C:\\Users\\Joo_Kai\\miniconda3\\envs\\cits5508-2023\\Lib\\typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Array, Dict, List, Tuple\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# To plot pretty figures\u001b[39;00m\n\u001b[0;32m     15\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Array' from 'typing' (C:\\Users\\Joo_Kai\\miniconda3\\envs\\cits5508-2023\\Lib\\typing.py)"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Importing useful libraries\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import Array, Dict, List, Tuple\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa31546c",
   "metadata": {},
   "source": [
    "# 2 Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e2c0dc",
   "metadata": {},
   "source": [
    "Read the contents of training.csv and testing.csv. It is assumed that both datasets are present in the root directory of this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca8494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "testing_data = pd.read_csv('testing.csv')\n",
    "training_data = pd.read_csv('training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd42eb5",
   "metadata": {},
   "source": [
    "## 2.1 Display the first lines and visualise dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40ad8a5",
   "metadata": {},
   "source": [
    "### 2.1.1 Display the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa8e9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Displaying the first 5 rows of the dataset\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e0d3f7",
   "metadata": {},
   "source": [
    "**TO DO describe the cells below** - watch the lecture on this part?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de76e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the different attributes/columns in the dataset\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "training_data.hist(bins=50, figsize=(20,15))\n",
    "save_fig(\"attribute_histogram_plots_training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c80df2",
   "metadata": {},
   "source": [
    "The majority of the histograms for each attribute are bell shaped. However, each arrtibute is skewed either to the left or the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46f3e2a",
   "metadata": {},
   "source": [
    "### 2.1.2 Displaying the Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the first 5 rows of the dataset\n",
    "testing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b75220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833fd7df",
   "metadata": {},
   "source": [
    "**TO DO describe the cells below** - watch the lecture on this part?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b912b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the different attributes/columns in the dataset\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "testing_data.hist(bins=50, figsize=(20,15))\n",
    "save_fig(\"attribute_histogram_plots_testing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de1772",
   "metadata": {},
   "source": [
    "## 2.2 Simplifying the Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ae5b6e",
   "metadata": {},
   "source": [
    "### 2.2.1 Removing Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77216acf",
   "metadata": {},
   "source": [
    "In order to simplify the classification task, the following scripts will delete all columns whose names begins with pred_minus_obs. This will leave 9 columns (features) for the training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee033405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function that allows us to drop all cols that start with a string\n",
    "def drop_cols(dataframe, start_string):\n",
    "    cols = list(dataframe) # create a list of dataframe columns\n",
    "    for i in cols:\n",
    "        if i.startswith(start_string):\n",
    "            dataframe.drop(i, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf6f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns from the two datasets \n",
    "drop_cols(training_data, 'pred_minus_obs')\n",
    "drop_cols(testing_data, 'pred_minus_obs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b57109",
   "metadata": {},
   "source": [
    "### 2.2.2 Counting Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004fef9d",
   "metadata": {},
   "source": [
    "The following code counts the number of instances for each class label in order to determine if we have a balanced dataset. We can view the output of the count_instances() function to determine the number of non-null instances in the dataset.\n",
    "\n",
    "It can be observed that the training data has an abundance of values for the s and d class label but a significantly lower proportion for values in the o and h class label.\n",
    "\n",
    "The testing data is more balanced in terms of s, d and h. However, it is also lacking in values for o. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b3cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a30bedf",
   "metadata": {},
   "source": [
    "### 2.2.3 Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d63590",
   "metadata": {},
   "source": [
    "The following code performs appropirate feature scaling on the datasets before doing the classification. The StandardScaler function from the sklearn.preprocessing package is used for this purpose. This puts it in more of a normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a91b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale(training: Array, testing: Array) -> Tuple[Array, Array]:\n",
    "    scaler = StandardScaler().fit(training)\n",
    "    training_scaled = scaler.transform(training)\n",
    "    testing_scaled = scaler.transform(testing)\n",
    "    return (training_scaled, testing_scaled)\n",
    "\n",
    "training_scaled, testing_scaled = scale(training_data, testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8b4ddf",
   "metadata": {},
   "source": [
    "To-do: \n",
    "1. Seperate into x and y labels for class and data\n",
    "3. scale that bictch\n",
    "2. Drop the o and h labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
