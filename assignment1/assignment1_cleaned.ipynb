{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e9e9ee9",
   "metadata": {},
   "source": [
    "# CITS5508 Assignment 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528b6e0",
   "metadata": {},
   "source": [
    "- Author: Joo Kai Tay (22489437)\n",
    "\n",
    "The following notebook contains code for classification tasks involving the Forest type mapping dataset for tasks 1 & 2 and the California Housing Proces dataset in task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826e0a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Importing useful libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49837d60",
   "metadata": {},
   "source": [
    "# 1 Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c897c",
   "metadata": {},
   "source": [
    "Read the contents of training.csv and testing.csv. It is assumed that both datasets are present in the root directory of this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "testing_data = pd.read_csv('testing.csv')\n",
    "training_data = pd.read_csv('training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47cb4bf",
   "metadata": {},
   "source": [
    "## 1.1 Display and visualise the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87943d9",
   "metadata": {},
   "source": [
    "The following two cells display the first rows of both the training and testing dataset. It can be seen by inspection that there are 28 columns that are part of this dataset which can be grouped into 4 distinct categories:\n",
    "- class: s, d, o, h\n",
    "    - These describe the 4 classes that make up this dataset\n",
    "- features b1 - b9\n",
    "- features that start with pred_minus_obs_H\n",
    "- features that start with pred_minus_obs_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b775109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the first 5 rows of the dataset\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the first 5 rows of the dataset\n",
    "testing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0744967e",
   "metadata": {},
   "source": [
    "## 1.2 Simpifying the classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e8047",
   "metadata": {},
   "source": [
    "The following cell removes all columns whose names begin with pred_minus_obs. This leaves only features b1-b9 in the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67cdc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9']\n",
    "training_data = training_data[['class'] + features]\n",
    "testing_data = testing_data[['class'] + features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283fb09",
   "metadata": {},
   "source": [
    "## 1.3 Visualizing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7e7b70",
   "metadata": {},
   "source": [
    "The following cells display the different features b1-b9 for the training dataset. The following observations can be gleaned from the plots:\n",
    "\n",
    "- Features b1, b4 and b7 seem to normally distributed.\n",
    "- Features b2, b3, b5, b6, b8 and b9 are skewed to the right \n",
    "\n",
    "***FIND OUT WHAT SKEWED DATASET REPRESENTS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72cc5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the different attributes/columns in the dataset\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "training_data.hist(bins=50, figsize=(20,15))\n",
    "save_fig(\"attribute_histogram_plots_training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8a5360",
   "metadata": {},
   "source": [
    "The following cells display the different features b1-b9 for the testing dataset. The observations that can be gleaned from the plots are very similar to that of the training dataset:\n",
    "\n",
    "- Features b1, b4 and b7 seem to normally distributed.\n",
    "- Features b2, b3, b5, b6, b8 and b9 are skewed to the right \n",
    "\n",
    "***FIND OUT WHAT SKEWED DATASET REPRESENTS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b895cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the different attributes/columns in the dataset\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "testing_data.hist(bins=50, figsize=(20,15))\n",
    "save_fig(\"attribute_histogram_plots_testing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ea5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f459ae",
   "metadata": {},
   "source": [
    "## 1.4 Counting class instances "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d60c41",
   "metadata": {},
   "source": [
    "The following code counts the number of instances for each class label in order to determine if we have a balanced dataset. We can view the output of the count_instances() function to determine the number of non-null instances in the dataset.\n",
    "\n",
    "It can be observed that the training data has an abundance of values for the s and d class label but a significantly lower proportion for values in the o and h class label.\n",
    "\n",
    "- 136 instances for class 's'\n",
    "- 105 instances for class 'd'\n",
    "- 46 instances for class 'o'\n",
    "- 38 instances for class 'h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurance of each label class and plot histogram\n",
    "\n",
    "instances = training_data['class'].value_counts()\n",
    "class_graph = instances.plot.bar(edgecolor='black', alpha=0.8)\n",
    "plt.xticks(rotation = 360)\n",
    "\n",
    "for rect in class_graph.patches:\n",
    "    height = rect.get_height()\n",
    "    x_position = rect.get_x() + rect.get_width() / 2\n",
    "    label = f\"{height:.0f}\"  # Format the label to be displayed\n",
    "    class_graph.annotate(label, (x_position, height), textcoords=\"offset points\", xytext=(0, 4), ha='center', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ba05f",
   "metadata": {},
   "source": [
    "## 2.5 Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cba52f",
   "metadata": {},
   "source": [
    "The following code performs appropirate feature scaling on the datasets before doing the classification. The StandardScaler function from the sklearn.preprocessing package is used for this purpose. Standardization scales the data to have a mean value of 0 and standard deviation of 1. This makes it more useful for the classification tasks that we are about to attempt.\n",
    "\n",
    "The function pre_process_data() returns a new copy of the training and testing dataset with the appropirate features/classes removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f4151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring variables to be passed to pre_process_data()\n",
    "\n",
    "features_all = ['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9'] # to be used for all 9 features\n",
    "classes_all = ['s', 'd', 'o', 'h'] # to be used for all classes\n",
    "classes_bin = ['s', 'd'] # to be used for classes 's' and 'd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6446f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Preparing the encoder\n",
    "enc_X = copy.deepcopy(training_data)\n",
    "enc_y = enc_X['class']\n",
    "\n",
    "# s = 0, d = 1, o = 2, h = 3\n",
    "enc = OrdinalEncoder(categories=[['s','d', 'o', 'h']])\n",
    "enc.fit(enc_y.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c9845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def pre_process_data(feature_arr, classes_arr):\n",
    "    # New scaler\n",
    "    scaler_func = StandardScaler()\n",
    "\n",
    "    # Preparing training data\n",
    "    train_X_func = copy.deepcopy(training_data)\n",
    "    \n",
    "    # Removes all instances of classes not in classes_arr\n",
    "    train_X_func = train_X_func[train_X_func['class'].isin(classes_arr)]\n",
    "    train_y_func = train_X_func['class']\n",
    "    \n",
    "    # Removes all but the feature we want\n",
    "    train_X_func = train_X_func[feature_arr]\n",
    "    train_X_func = scaler_func.fit_transform(train_X_func.values)\n",
    "    \n",
    "    # Preparing testing data\n",
    "    test_X_func = copy.deepcopy(testing_data)\n",
    "    # Removes all instances of classes not in classes_arr\n",
    "    test_X_func = test_X_func[test_X_func['class'].isin(classes_arr)]\n",
    "    test_y_func = test_X_func['class']\n",
    "    \n",
    "    # Removes all but the feature we want\n",
    "    test_X_func = test_X_func[feature_arr]\n",
    "    test_X_func = scaler_func.transform(test_X_func.values)\n",
    "    \n",
    "    # Encodes y values using ordinal encoder\n",
    "    train_y_func = enc.transform(train_y_func.values.reshape(-1,1)) \n",
    "    test_y_func = enc.transform(test_y_func.values.reshape(-1,1)) \n",
    "    \n",
    "    return train_X_func, train_y_func, test_X_func, test_y_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1242e22",
   "metadata": {},
   "source": [
    "## 1.6 Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e018973",
   "metadata": {},
   "source": [
    "This section will perform binary classification using the logistic regression classifier on features b1 and b2. Only example from two classes: 's' and 'd' will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d01b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "feature_bin = ['b1']\n",
    "train_X_b1, train_y_b1, test_X_b1, test_y_b1 = pre_process_data(feature_bin, classes_bin)\n",
    "\n",
    "# Creating an instance of the logistic regression classifier and fitting it on the training data\n",
    "log_reg_b1 = LogisticRegression(random_state=42)\n",
    "log_reg_b1.fit(train_X_b1, train_y_b1.ravel())\n",
    "\n",
    "# Making predictions on the testing data\n",
    "y_pred_b1 = log_reg_b1.predict(test_X_b1)\n",
    "\n",
    "# Evaluation of model performance\n",
    "accuracy_b1 = accuracy_score(test_y_b1, y_pred_b1)\n",
    "report_b1 = classification_report(test_y_b1, y_pred_b1)\n",
    "\n",
    "print(\"Accuracy of Logistic Regression Classifier on b1:\", accuracy_b1)\n",
    "print(\"\\nReport on Classification:\\n\", report_b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e83d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_bin = ['b2']\n",
    "train_X_b2, train_y_b2, test_X_b2, test_y_b2 = pre_process_data(feature_bin, classes_bin)\n",
    "\n",
    "# Creating an instance of the logistic regression classifier and fitting it on the training data\n",
    "log_reg_b2 = LogisticRegression(random_state=42)\n",
    "log_reg_b2.fit(train_X_b2, train_y_b2.ravel())\n",
    "\n",
    "# Making predictions on the testing data\n",
    "y_pred_b2 = log_reg_b2.predict(test_X_b2)\n",
    "\n",
    "# Evaluation of model performance\n",
    "accuracy_b2 = accuracy_score(test_y_b2, y_pred_b2)\n",
    "report_b2 = classification_report(test_y_b2, y_pred_b2)\n",
    "\n",
    "print(\"Accuracy of Logistic Regression Classifier on b2:\", accuracy_b2)\n",
    "print(\"\\nReport on Classification:\\n\", report_b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658ddbf7",
   "metadata": {},
   "source": [
    "## 1.7 Estimated Probabilities and Decision Boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c9cca",
   "metadata": {},
   "source": [
    "### 1.7.1 Plotting estimated probabilities and decision boundary for logistic regression classifier considering 1 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ca946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def plot_graph(feature_bin, X, y, dec_bound, flag):\n",
    "    plt.figure(figsize=(8, 3))  # extra code – not needed, just formatting\n",
    "    plt.plot(X, y[:,0], \"b--\", linewidth=2,\n",
    "             label=\"s proba\")\n",
    "    plt.plot(X, y[:,1], \"g-\", linewidth=2, label=\"d proba\")\n",
    "    plt.plot([dec_bound, dec_bound], [0, 1], \"k:\", linewidth=2,\n",
    "             label=\"Decision boundary\")\n",
    "\n",
    "    # extra code – this section beautifies and saves Figure 4–23\n",
    "    plt.arrow(x=dec_bound, y=0.92, dx=0.3, dy=0,\n",
    "              head_width=0.05, head_length=0.1, fc=\"b\", ec=\"b\")\n",
    "    plt.arrow(x=dec_bound, y=0.08, dx=-0.3, dy=0,\n",
    "              head_width=0.05, head_length=0.1, fc=\"g\", ec=\"g\")\n",
    "    \n",
    "    if flag == 'Y':\n",
    "        test_vals_x = np.zeros(shape=(10,1))\n",
    "        test_vals_y = np.empty(shape=(10,1))\n",
    "        \n",
    "        for idx in range(10):\n",
    "            value = random.randint(0,test_X_b1.size - 1)\n",
    "            test_vals_x[idx] = np.dot(np.atleast_2d(test_X_all[idx]), coef_matrix.T) + bias\n",
    "            test_vals_y[idx] = test_y_all[value]\n",
    "        \n",
    "        plt.plot(test_vals_x[test_vals_y == 0], test_vals_y[test_vals_y == 0], \"g^\")\n",
    "        plt.plot(test_vals_x[test_vals_y == 1], test_vals_y[test_vals_y == 1], \"bs\")\n",
    "    \n",
    "    plt.xlabel(feature_bin)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.legend(loc=\"center right\")\n",
    "    plt.axis([X.min(), X.max(), y.min() - 0.05, y.max() + 0.05])\n",
    "    plt.grid()\n",
    "    save_fig(\"logistic_regression_plot\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f341e",
   "metadata": {},
   "source": [
    "### 1.7.1.1 Feature b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bbb141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate even spaced 1000 datapoints\n",
    "X_new = np.linspace(train_X_b1.min() - 5, train_X_b1.max() + 5, 1000).reshape(-1,1)\n",
    "y_proba = log_reg_b1.predict_proba(X_new)\n",
    "\n",
    "decision_boundary = X_new[y_proba[:, 0] >= 0.5][0, 0]\n",
    "\n",
    "print('Decision boundary for feature b1:', decision_boundary)\n",
    "\n",
    "plot_graph('b1', X_new, y_proba, decision_boundary, 'N')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a318a2",
   "metadata": {},
   "source": [
    "### 1.7.1.2 Feature b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33ccbbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate even spaced 1000 datapoints\n",
    "X_new = np.linspace(train_X_b2.min() - 5, train_X_b2.max() + 5, 1000).reshape(-1,1)\n",
    "y_proba = log_reg_b2.predict_proba(X_new)\n",
    "\n",
    "decision_boundary = X_new[y_proba[:, 0] <= 0.5][0, 0]\n",
    "\n",
    "print('Decision boundary for feature b2:', decision_boundary)\n",
    "\n",
    "plot_graph('b2', X_new, y_proba, decision_boundary, 'N')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8beb457",
   "metadata": {},
   "source": [
    "### 1.7.2 Logistic Regression Classifier with all 9 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deb4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_all, train_y_all, test_X_all, test_y_all = pre_process_data(features_all, classes_bin)\n",
    "\n",
    "# Creating an instance of the logistic regression classifier and fitting it on the training data\n",
    "log_reg_all = LogisticRegression(random_state=42)\n",
    "log_reg_all.fit(train_X_all, train_y_all.ravel())\n",
    "\n",
    "# Making predictions on the testing data\n",
    "y_pred_all = log_reg_all.predict(test_X_all)\n",
    "\n",
    "# Evaluation of model performance\n",
    "accuracy_all = accuracy_score(test_y_all, y_pred_all)\n",
    "report_all = classification_report(test_y_all, y_pred_all)\n",
    "\n",
    "print(\"Accuracy of Logistic Regression Classifier on all 9 features:\", accuracy_all)\n",
    "print(\"\\nReport on Classification:\\n\", report_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a6fa80",
   "metadata": {},
   "source": [
    "The following cell plots the estimated probabilities and decision boundary for a model considering all features. This is done using the score value of the linear part from the logistic regression model in the x-axis.\n",
    "\n",
    "10 instances of the testing set are then added to the plot and verfied if the classifier has made a correct decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a35539a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coef_matrix = log_reg_all.coef_ # Coefficient of the features in the decision function\n",
    "bias = log_reg_all.intercept_   # Bias term added to the decision function \n",
    "\n",
    "num_rows, num_cols = train_X_all.shape\n",
    "x_axis = np.zeros(shape=(num_rows,1))\n",
    "y_axis = np.zeros(shape=(num_rows,1))\n",
    "\n",
    "# Computes the dot product of the training data with the coefficient terms and add the bias term to obtain the score value\n",
    "for idx in range(num_rows):\n",
    "    x_axis[idx] = np.dot(np.atleast_2d(train_X_all[idx]), coef_matrix.T) + bias\n",
    "\n",
    "# Get the probability predictions based on the score value\n",
    "y_axis = log_reg_all.predict_proba(train_X_all)\n",
    "\n",
    "# Sort both arrays in ascending order for smooth plotting\n",
    "x_axis, y_axis = zip(*sorted(zip(x_axis, y_axis)))\n",
    "\n",
    "decision_boundary_all = np.array(x_axis)[np.array(y_axis)[:, 1] >= 0.5][0, 0]\n",
    "print('Decision boundary for feature all 9 features:', decision_boundary_all)\n",
    "plot_graph('Score Value', np.array(x_axis), np.array(y_axis), decision_boundary_all, 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ae0d79",
   "metadata": {},
   "source": [
    "## 1.8 Precision vs Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c7777",
   "metadata": {},
   "source": [
    "### 1.8.1 Precision and recall vs threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17aa204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_scores = cross_val_predict(log_reg_all, train_X_all, train_y_all.ravel(), cv=3,\n",
    "                             method=\"decision_function\")\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(train_y_all, y_scores)\n",
    "threshold = 1\n",
    "\n",
    "plt.figure(figsize=(8, 4))  # extra code – it's not needed, just formatting\n",
    "plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "plt.vlines(threshold, 0, 1.0, \"k\", \"dotted\", label=\"threshold\")\n",
    "\n",
    "# extra code – this section just beautifies and saves Figure 3–5\n",
    "idx = (thresholds >= threshold).argmax()  # first index ≥ threshold\n",
    "plt.plot(thresholds[idx], precisions[idx], \"bo\")\n",
    "plt.plot(thresholds[idx], recalls[idx], \"go\")\n",
    "plt.axis([-8, 5, 0, 1.2])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend(loc=\"center right\")\n",
    "save_fig(\"precision_recall_vs_threshold_plot\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c778c26f",
   "metadata": {},
   "source": [
    "### 1.8.2 Precision vs recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d6d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches  # extra code – for the curved arrow\n",
    "\n",
    "plt.figure(figsize=(6, 5))  # extra code – not needed, just formatting\n",
    "\n",
    "plt.plot(recalls, precisions, linewidth=2, label=\"Precision/Recall curve\")\n",
    "\n",
    "# extra code – just beautifies and saves Figure 3–6\n",
    "plt.plot([recalls[idx], recalls[idx]], [0., precisions[idx]], \"k:\")\n",
    "plt.plot([0.0, recalls[idx]], [precisions[idx], precisions[idx]], \"k:\")\n",
    "plt.plot([recalls[idx]], [precisions[idx]], \"ko\",\n",
    "         label=\"Point at threshold 3,000\")\n",
    "plt.gca().add_patch(patches.FancyArrowPatch(\n",
    "    (0.79, 0.60), (0.61, 0.78),\n",
    "    connectionstyle=\"arc3,rad=.2\",\n",
    "    arrowstyle=\"Simple, tail_width=1.5, head_width=8, head_length=10\",\n",
    "    color=\"#444444\"))\n",
    "plt.text(0.56, 0.62, \"Higher\\nthreshold\", color=\"#333333\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.axis([0.4, 1.1, 0.5, 1.0])\n",
    "plt.grid()\n",
    "plt.legend(loc=\"lower left\")\n",
    "save_fig(\"precision_vs_recall_plot\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29bca8",
   "metadata": {},
   "source": [
    "## 1.9 K-Nearest-Neighbour (kNN) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e9ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "train_X_knn, train_y_knn, test_X_knn, test_y_knn = pre_process_data(features_all, classes_bin)\n",
    "\n",
    "kNN = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='auto', p=1)\n",
    "kNN.fit(train_X_knn, train_y_knn.ravel())\n",
    "\n",
    "# Making predictions on the testing data\n",
    "y_pred_knn = kNN.predict(test_X_knn)\n",
    "\n",
    "# Evaluation of model performance\n",
    "accuracy_knn = accuracy_score(test_y_knn, y_pred_knn)\n",
    "report_knn = classification_report(test_y_knn, y_pred_knn)\n",
    "\n",
    "print(\"Accuracy of Logistic Regression Classifier on all 9 features:\", accuracy_knn)\n",
    "print(\"\\nReport on Classification:\\n\", report_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223f468a",
   "metadata": {},
   "source": [
    "## 1.10 Comparing Logistic Regression and kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a875d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def plot_roc(y_stuff, y_scores_stuff, label=None):\n",
    "    fpr, tpr, threshold = roc_curve(y_stuff, y_scores_stuff.ravel())\n",
    "\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k:', label=\"Random classifier's ROC curve\")\n",
    "\n",
    "    # extra code – just beautifies and saves Figure 3–7\n",
    "    plt.xlabel('False Positive Rate (Fall-Out)')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.grid()\n",
    "    plt.axis([0, 1, 0, 1.1])\n",
    "    plt.legend(loc=\"lower right\", fontsize=13)\n",
    "    save_fig(\"roc_curve_plot\")\n",
    "    plt.grid(True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d372d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_log = cross_val_predict(log_reg_all, test_X_all, test_y_all.ravel(), cv=3)\n",
    "y_scores_knn = cross_val_predict(kNN, test_X_knn, test_y_knn.ravel(), cv=3)\n",
    "\n",
    "fig_roc = plt.figure(figsize=(12,9))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plot_roc(test_y_all, y_scores_log)\n",
    "plt.title('ROC - Logistic Regression All Features')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plot_roc(test_y_knn, y_scores_knn)\n",
    "plt.title('ROC - kNN All Features')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32cf16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "plt.rc('font', size=9)  \n",
    "ConfusionMatrixDisplay.from_predictions(enc.inverse_transform(test_y_all), enc.inverse_transform(y_scores_log.reshape(-1,1)))\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "\n",
    "plt.rc('font', size=9)  # extra code – make the text smaller\n",
    "ConfusionMatrixDisplay.from_predictions(enc.inverse_transform(test_y_knn), enc.inverse_transform(y_scores_knn.reshape(-1,1)))\n",
    "plt.title('Confusion Matrix - kNN')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac1a5f",
   "metadata": {},
   "source": [
    "## 1.11 Cross Validation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c963a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 3-fold cross-validation \n",
    "cv_scores_log_reg = cross_val_score(log_reg_all, test_X_all, test_y_all.ravel(), cv=3)\n",
    "cv_scores_knn = cross_val_score(kNN, test_X_knn, test_y_knn.ravel(), cv=3)\n",
    "\n",
    "# Print Array of scores of the estimator for each run of the cross validation.\n",
    "print(\"Logistic Regression CV scores:\", cv_scores_log_reg)\n",
    "print(\"k-NN CV scores:\", cv_scores_knn)\n",
    "\n",
    "# Print average cross-validation scores\n",
    "print(\"Logistic Regression average CV score:\", cv_scores_log_reg.mean())\n",
    "print(\"k-NN average CV score:\", cv_scores_knn.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3d4a6",
   "metadata": {},
   "source": [
    "# 2 Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf819ca",
   "metadata": {},
   "source": [
    "The following steps will be performed with all classes in the Forest type mapping Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7374f9",
   "metadata": {},
   "source": [
    "## 2.1 Support Vector Machine Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a66e732",
   "metadata": {},
   "source": [
    "Use the Support Vector Machine Classifier implemented in the sklearn.svm.SVC class to perform multiclass classification using the one-versus-one strategy. \n",
    "\n",
    "Use grid search and 3-fold cross validation to find the optimal values for the two hyper parameters \n",
    "\n",
    "Hyper parameters:\n",
    "- C (regularization parameter)\n",
    "- kernel (linear, poly, rbf, sigmoid, precomputed)\n",
    "- degree (only for poly kernel)\n",
    "- gamma (rbf, poly, sigmoid)\n",
    "- coef0 (poly and sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11fbe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Getting new instances of the training and testing set\n",
    "train_X_svc, train_y_svc, test_X_svc, test_y_svc = pre_process_data(features_all, classes_all)\n",
    "\n",
    "# Create an SVM classifier using the hyperparameter decision_function_shape='ovo' for a one-versus-one strategy\n",
    "svc = SVC(decision_function_shape='ovo')\n",
    "\n",
    "# Define the hyperparameters and their possible values for grid search\n",
    "param_grid = {\n",
    "    'C': [0.1, 5, 50],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Create a grid search object with 3-fold cross-validation\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "grid_search.fit(train_X_svc, np.ravel(train_y_svc))\n",
    "\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best cross-validation score\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the classifier with the best hyperparameters on the test set\n",
    "best_svc = grid_search.best_estimator_\n",
    "test_accuracy = best_svc.score(train_X_svc, np.ravel(train_y_svc))\n",
    "print(\"Test set accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26d9cd0",
   "metadata": {},
   "source": [
    "## 2.2 Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d77ce0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Getting new instances of the training and testing set\n",
    "train_X_softmax, train_y_softmax, test_X_softmax, test_y_softmax = pre_process_data(features_all, classes_all)\n",
    "\n",
    "# Define the hyperparameters and their possible values for grid search\n",
    "param_grid = {\n",
    "    'C': [1, 2, 10],\n",
    "    'solver': ['lbfgs', 'newton-cg']\n",
    "}\n",
    "\n",
    "softmax = LogisticRegression(multi_class='multinomial')\n",
    "\n",
    "# Create a grid search object with 3-fold cross-validation\n",
    "grid_search = GridSearchCV(softmax, param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "grid_search.fit(train_X_softmax, np.ravel(train_y_softmax))\n",
    "\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best cross-validation score\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the classifier with the best hyperparameters on the test set\n",
    "best_svc = grid_search.best_estimator_\n",
    "test_accuracy = best_svc.score(train_X_softmax, np.ravel(train_y_softmax))\n",
    "print(\"Test set accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa38488",
   "metadata": {},
   "source": [
    "## 2.3 kNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e3bfd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Getting new instances of the training and testing set\n",
    "train_X_kNN1, train_y_kNN1, test_X_kNN1, test_y_kNN1 = pre_process_data(features_all, classes_all)\n",
    "\n",
    "# Define the hyperparameters and their possible values for grid search\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 19, 9],\n",
    "    'algorithm': ['ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "kNN1 = KNeighborsClassifier()\n",
    "\n",
    "# Create a grid search object with 3-fold cross-validation\n",
    "grid_search = GridSearchCV(kNN1, param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "grid_search.fit(train_X_kNN1, np.ravel(train_y_kNN1))\n",
    "\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best cross-validation score\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the classifier with the best hyperparameters on the test set\n",
    "best_svc = grid_search.best_estimator_\n",
    "test_accuracy = best_svc.score(train_X_kNN1, np.ravel(train_y_kNN1))\n",
    "print(\"Test set accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc604595",
   "metadata": {},
   "source": [
    "# 3 Implementing k-NN algorithm to do regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83819c46",
   "metadata": {},
   "source": [
    "The following cells use the class KNeighborsRegressor to perform regression on the California Housing Prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf71089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "def load_housing_data():\n",
    "    tarball_path = Path(\"datasets/housing.tgz\")\n",
    "    if not tarball_path.is_file():\n",
    "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
    "        url = \"https://github.com/ageron/data/raw/main/housing.tgz\"\n",
    "        urllib.request.urlretrieve(url, tarball_path)\n",
    "        with tarfile.open(tarball_path) as housing_tarball:\n",
    "            housing_tarball.extractall(path=\"datasets\")\n",
    "    return pd.read_csv(Path(\"datasets/housing/housing.csv\"))\n",
    "\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44486db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58526e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43bea3c",
   "metadata": {},
   "source": [
    "## 3.1 Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466094a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the encoder\n",
    "enc_cat = OrdinalEncoder()\n",
    "# Encodes the ocean proximity category\n",
    "housing['ocean_proximity'] = enc_cat.fit_transform(housing['ocean_proximity'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b04cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "housing_transformed = imputer.fit_transform(housing)\n",
    "\n",
    "housing = pd.DataFrame(housing_transformed, columns=housing.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391ebceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into a training set (80%) and a testing set (20%)\n",
    "housing_train, housing_test = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting training set into x and y components\n",
    "housing_train_X = housing_train.drop(\"median_house_value\", axis=1)\n",
    "housing_train_y = housing_train[\"median_house_value\"].copy()\n",
    "\n",
    "# Splitting testing set into x and y components\n",
    "housing_test_X = housing_test.drop(\"median_house_value\", axis=1)\n",
    "housing_test_y = housing_test[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9545e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler_housing = StandardScaler()\n",
    "\n",
    "cols = housing.drop(\"median_house_value\", axis=1)\n",
    "\n",
    "# Fit the standard scaler to the training set\n",
    "housing_train_X = standard_scaler_housing.fit_transform(housing_train_X)\n",
    "housing_train_X_scaled = pd.DataFrame(housing_train_X, columns=cols.columns)\n",
    "\n",
    "\n",
    "# Transform the testing set\n",
    "housing_test_X = standard_scaler_housing.transform(housing_test_X)\n",
    "housing_test_X_scaled = pd.DataFrame(housing_test_X, columns=cols.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffda43c",
   "metadata": {},
   "source": [
    "## 3.2 RMSE of whole set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c4f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "kNN_reg = KNeighborsRegressor(n_neighbors=5)\n",
    "kNN_reg.fit(housing_train_X, housing_train_y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = kNN_reg.predict(housing_test_X)\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(housing_test_y, y_pred))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a045abd0",
   "metadata": {},
   "source": [
    "## 3.3 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d948a5a3",
   "metadata": {},
   "source": [
    "Feature importance scores are used to determine the relativve importance of each feature in the housing dataset. The following cells will show two methods: linear regression and random forest to obtain the feature importance. The features that show up as the most important will be selected to train the KNeighborsRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc11ffc1",
   "metadata": {},
   "source": [
    "### 3.3.1 Feature Selection with linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a91fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_log_reg = LogisticRegression()\n",
    "selector_log_reg.fit(housing_train_X, housing_train_y)\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': housing_train_X_scaled.columns,\n",
    "    'Importance': selector_log_reg.coef_[0]\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='#087E8B')\n",
    "plt.title('Feature importances obtained from coefficients', size=20)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9a50e7",
   "metadata": {},
   "source": [
    "### 3.3.2 Feature Selection with random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0335ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "selector_random_forest = RandomForestRegressor()\n",
    "selector_random_forest.fit(housing_train_X, housing_train_y)\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': housing_train_X_scaled.columns,\n",
    "    'Importance': selector_random_forest.feature_importances_\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='#087E8B')\n",
    "plt.title('Feature importances obtained from coefficients', size=20)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb9aa73",
   "metadata": {},
   "source": [
    "## 3.4 k Neighbors Regressor with selected data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d2df5a",
   "metadata": {},
   "source": [
    "The features ranked by importance from the logistic regressor:\n",
    "- Total rooms\n",
    "- Median Income\n",
    "- Latitude\n",
    "- Longitude\n",
    "- Population\n",
    "- Households\n",
    "- Total bedrooms\n",
    "- Housing median age\n",
    "- Ocean proximity\n",
    "\n",
    "The features ranked by importance from the random forest regressor:\n",
    "- Median Income\n",
    "- Ocean proximity\n",
    "- Latitude\n",
    "- Longitude\n",
    "- Housing median age\n",
    "- Population\n",
    "- Total rooms\n",
    "- Total bedrooms\n",
    "- Households\n",
    "\n",
    "Based on this data, 6 features were chosen to train the model:\n",
    "- Median Income\n",
    "- Ocean proximity\n",
    "- Latitude\n",
    "- Longitude\n",
    "- Total rooms\n",
    "- Population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efdcb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_kNN_reg = ['median_income', 'longitude', 'latitude', 'ocean_proximity', 'population', 'total_rooms']\n",
    "train_X_selected = housing_train_X[features_kNN_reg]\n",
    "test_X_selected = housing_test_X[features_kNN_reg]\n",
    "\n",
    "# Train k-NN regressors with 'uniform' and 'distance' weights\n",
    "knn_uniform = KNeighborsRegressor(n_neighbors=5, weights='uniform')\n",
    "knn_distance = KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "\n",
    "knn_uniform.fit(train_X_selected, housing_train_y)\n",
    "knn_distance.fit(train_X_selected, housing_train_y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_uniform = knn_uniform.predict(test_X_selected)\n",
    "y_pred_distance = knn_distance.predict(test_X_selected)\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse_uniform = np.sqrt(mean_squared_error(housing_test_y, y_pred_uniform))\n",
    "print(\"RMSE with uniform weights is:\", rmse)\n",
    "\n",
    "rmse_distance = np.sqrt(mean_squared_error(housing_test_y, y_pred_distance))\n",
    "print(\"RMSE with distance weights is:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e4ab87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
